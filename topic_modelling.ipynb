{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MIiZIbWf45Y8"
   },
   "source": [
    "# Implementação - Topic Modelling com LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "zRPYPfGG45Y_"
   },
   "source": [
    "Existem muitas implementações boas de Topic Modelling usando LDA, tanto em Python quanto em R (preferido de David Blei). Assim, o desafio é como extrair boa qualidade de tópicos claros, segregados e significativos.Isto depende muito da qualidade de pre-processamento de texto e da estratégia de encontrar o número ótimo de tópicos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "jZMWzSW145ZB"
   },
   "source": [
    "Aqui vamos utilizar, mais uma vez, o pacote gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBA5e_cB45ZC"
   },
   "source": [
    "## Importante: Execute esse tutorial no jupyterlab para evitar problemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_v3sMlgX45ZE"
   },
   "outputs": [],
   "source": [
    "!pip install pprint\n",
    "!pip install pyLDAvis\n",
    "# python -m spacy download en - executar pelo terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nl7JbGyw45ZN",
    "outputId": "9f2a1c12-7515-424e-f8cf-b2221f993968"
   },
   "outputs": [],
   "source": [
    "import nltk; nltk.download('stopwords')\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPRMq0VD45ZZ"
   },
   "outputs": [],
   "source": [
    "# Stop-words: para o conjunto a ser analisado, precisamos adicionar mais algumas stop-words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "ZoT7blH745Ze"
   },
   "source": [
    "Vamos utilizar o 20-Newsgroups dataset para esse exercício. O conjunto é composto por aproximadamente 11k amostras distribuídas em 20 diferentes tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6-2--5t45Zg",
    "outputId": "f0b55187-65e5-45fb-ece0-1b98823625a0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "print(df.target_names.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "fQlVp1OL45Zo"
   },
   "source": [
    "Pelos exemplos mostrados acima, podemos observar que existem muitos emails, caracter de nova linha (\\n) e há também espaços extras. Vamos tratar isso usando regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFQLDB-R45Z1"
   },
   "outputs": [],
   "source": [
    "# Converte para lista\n",
    "data = df.content.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove caracter de nova linha\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove aspas simples\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "yUrsTyAa45Z7"
   },
   "source": [
    "O texto ainda está bagunçado e, portanto, não pronto para executar LDA. Precisamos tokenizar e deixá-lo mais limpo. Para isso, vamos usar gensim simple_preprocess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nd_o6a6s45Z8"
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True remove pontuação\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "phBymtaT45aF"
   },
   "source": [
    "Agora, podemos criar bigramas (duas palavras que frequentemente ocorrem no documento) e trigramas (3 palavras que ocorrem frequentemente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_zEfxl345aH"
   },
   "outputs": [],
   "source": [
    "# cria modelos bigrama e trigrama\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # quanto maior o threshold menos frases\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Maneira mais rápida de obter uma sentença como um trigrama / bigrama\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# exemplo trigrama\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1UR0ZbxF45aO"
   },
   "source": [
    "Agora precisamos remover stop-words, criar bigramas sobre o texto e lematizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxTTvi9t45aP"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdxOt6aC45aU"
   },
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# cria Bigramas\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# inicia o spacy, mantenddo apenas o tagger (eficiência)\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# faz lemmatização mantendo apenas substantivo, adjetivo, verbo, advérbio\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "BRjmCu3J45aZ"
   },
   "source": [
    "Agora precisamos criar o dicionário e o corpus para executar o LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QEJ-SA-J45ab"
   },
   "outputs": [],
   "source": [
    "# cria o dicionário\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Cria o corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "8RJQXNwx45ai"
   },
   "source": [
    "Gensim cria um id exclusivo para cada palavra no documento. O corpus produzido mostrado acima é um mapeamento de (word_id, word_frequency).\n",
    "\n",
    "Por exemplo, (0, 1) acima implica que a palavra cujo id é 0 ocorre uma vez no primeiro documento. Da mesma forma, a palavra id 1 ocorre duas vezes e assim por diante.\n",
    "\n",
    "Isso é usado como entrada pelo modelo LDA.\n",
    "\n",
    "Se você quiser ver a palavra que um determinado id corresponde, passe o id como uma chave para o dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_ZUttow45aj"
   },
   "outputs": [],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "fnf4AUpe45ar"
   },
   "source": [
    "Temos tudo o que é necessário para treinar o modelo LDA. Além do corpus e do dicionário, você também precisa fornecer o número de tópicos.\n",
    "\n",
    "Além disso, alfa e eta são hiperparâmetros que afetam a dispersão dos tópicos. De acordo com os documentos do Gensim, o padrão é 1.0 / num_topics anterior.\n",
    "\n",
    "chunksize é o número de documentos a serem usados em cada bloco de treinamento. update_every determina com que frequência os parâmetros do modelo devem ser atualizados e passes é o número total de passes de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fbPSb5qQ45at"
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "Zm3s6GWB45a3"
   },
   "source": [
    "O modelo de LDA acima é construído com 20 tópicos diferentes, em que cada tópico é uma combinação de palavras-chave e cada palavra-chave contribui com um certo peso para o tópico.\n",
    "\n",
    "Você pode ver as palavras-chave de cada tópico e a ponderação (importância) de cada palavra-chave usando lda_model.print_topics () como mostrado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bESlePRY45a5"
   },
   "outputs": [],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "sFwG-vNi45bC"
   },
   "source": [
    "Como interpretar isso?\n",
    "\n",
    "O tópico 0 é representado como 0.140*\"window\" + 0.111*\"file\" + 0.044*\"server\" + 0.042*\"mode\" + ' '0.041*\"available\" + 0.036*\"peter\" + 0.028*\"faq\" + 0.027*\"information\" + ''0.021*\"source\" + 0.020*\"application\".\n",
    "\n",
    "Isso significa que as 10 principais palavras-chave que contribuem para esse tópico são: \"window\", \"file\", \"server\" ... e assim por diante, e o peso de \"winddow\" no tópico 0 é 0,140.\n",
    "\n",
    "Os pesos refletem a importância de uma palavra-chave para esse tópico.\n",
    "\n",
    "Olhando para essas palavras-chave, você pode adivinhar o que este tópico poderia ser? Você pode resumir que são \"computador\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsFYvyNi45bH"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"topics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "9sh5FtI345bW"
   },
   "source": [
    "Perplexidade de modelo e coerência de tópico fornecem uma medida conveniente para julgar quão bom é um determinado modelo de tópico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oozkEve45bb"
   },
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # uma medida de quão bom o modelo é. quanto maiss baaixa, melhor\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "BiqBRqmy45bh"
   },
   "source": [
    "Agora que o modelo de LDA foi criado, a próxima etapa é examinar os tópicos produzidos e as palavras-chave associadas. Não há ferramenta melhor do que o gráfico interativo do pacote pyLDAvis e foi projetado para funcionar bem com os Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCLuh1wg45bi"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "g9xbI5eD45bn"
   },
   "source": [
    "Então, como inferir a saída do pyLDAvis?\n",
    "\n",
    "Cada bolha no gráfico do lado esquerdo representa um tópico. Quanto maior a bolha, mais prevalente é esse tópico.\n",
    "\n",
    "Um bom modelo de tópico terá bolhas grandes e não sobrepostas espalhadas pelo gráfico, em vez de estarem agrupadas em um quadrante.\n",
    "\n",
    "Um modelo com muitos tópicos geralmente terá muitas sobreposições, bolhas de tamanho pequeno agrupadas em uma região do gráfico.\n",
    "\n",
    "Ok, se você mover o cursor sobre uma das bolhas, as palavras e barras do lado direito serão atualizadas. Essas palavras são as palavras-chave salientes que formam o tópico selecionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "yAbujs4s45bp"
   },
   "source": [
    "De antemão, sabíamos o número ótimo de tópicos, mas e em situações em que essa informação é desconhecida?\n",
    "\n",
    "Podemos criar uma forma de determinar o melhor número de tópicos (semelhante ao elbow para cluster)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "SqjMMntr45br"
   },
   "source": [
    "A abordagem para encontrar o número ideal de tópicos é construir muitos modelos de LDA com diferentes valores de número de tópicos (k) e escolher aquele que fornece o maior valor de coerência.\n",
    "\n",
    "A escolha de um \"k\" que marca o fim de um rápido crescimento da coerência dos tópicos geralmente oferece tópicos significativos e interpretáveis. Escolher um valor ainda mais alto pode, às vezes, fornecer sub-tópicos mais granulares.\n",
    "\n",
    "Se você perceber que as mesmas palavras-chave estão sendo repetidas em vários tópicos, provavelmente é um sinal de que o \"k\" é muito grande.\n",
    "\n",
    "O compute_coherence_values () (veja abaixo) treina vários modelos de LDA e fornece os modelos e suas pontuações de coerência correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V1MpkRlS45bs"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpfClYUP45bz"
   },
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=30, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdHsq-wO45b3"
   },
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5Eo94pi45b7"
   },
   "outputs": [],
   "source": [
    "# Visualizando os resultados\n",
    "limit=30; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xP6p3VVQ45cB"
   },
   "outputs": [],
   "source": [
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "it2k7JLh45cF"
   },
   "outputs": [],
   "source": [
    "lda_model[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2406gz045cJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "topic_modelling.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
