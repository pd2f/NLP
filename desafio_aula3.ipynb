{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio - Aula 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from unicodedata import normalize\n",
    "\n",
    "nltk.download('wordnet')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Crie uma classe de tratamento de texto. A classe deverá conter:\n",
    "   ## -> remoção de números\n",
    "   ## -> passar o texto para caixa baixa\n",
    "   ## -> remoção de caracteres especiais\n",
    "   ## -> remoção de stop-words\n",
    "   ## -> Stemização/lemmatização (deve ser passado como parâmetro qual abordagem utilizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_caracteres(txt):\n",
    "    txt=[normalize('NFKD',x).encode('ASCII','ignore').decode('ASCII') for x in txt]\n",
    "    txt=[re.sub('[^a-z|\\ ]','',str.lower(x)) for x in txt]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stop_words(txt):\n",
    "    texto = CountVectorizer(ngram_range=(1,1),stop_words=stop_words)\n",
    "    texto.fit(txt)\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tratar_texto(txt,metodo=''):\n",
    "    txt = trata_caracteres(txt)\n",
    "    try:\n",
    "        texto = remove_stop_words(txt)\n",
    "        lista_txt = texto.get_feature_names()\n",
    "    except:\n",
    "        lista_txt = txt\n",
    "    if metodo=='lemma':\n",
    "        lem = WordNetLemmatizer()\n",
    "        for part_of_speech in ['a', 's', 'r', 'n', 'v']:\n",
    "            tms = [lem.lemmatize(a,part_of_speech) for a in lista_txt]\n",
    "    if metodo == 'stem':\n",
    "        ps = PorterStemmer()\n",
    "        tms = [ps.stem(a) for a in lista_txt]\n",
    "    if metodo == '':\n",
    "        tms = txt\n",
    "    return \" \".join(tms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Refaça o exercício de aula (movie_review) realizando o tratamento do texto antes. Houve diferença? Descreva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('movie_review1.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sw'] = data.text.apply(lambda x: tratar_texto([x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texto Puro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "vector = vec.fit_transform(data.text)\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, data.tag, test_size=0.3, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados da predição sem Tratamento do Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.71      0.71      9561\n",
      "          1       0.72      0.70      0.71      9855\n",
      "\n",
      "avg / total       0.71      0.71      0.71     19416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusão de resultados com texto puro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito     0     1\n",
      "Real               \n",
      "0        6828  2733\n",
      "1        2938  6917\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(y_test,predicted,rownames=['Real'],colnames=['Predito'],margins=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia da predição sem tratamento de texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7079213020189534\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(predicted == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminados caracteres especiais e Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_sw = CountVectorizer()\n",
    "vector_sw = vec.fit_transform(data.sw)\n",
    "X_train_sw, X_test_sw, y_train_sw, y_test_sw = train_test_split(vector_sw, data.tag, test_size=0.3, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sw = MultinomialNB().fit(X_train_sw, y_train_sw)\n",
    "predicted_sw = model_sw.predict(X_test_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados com Tratamento de texto 'Stop Words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70      9561\n",
      "          1       0.71      0.70      0.71      9855\n",
      "\n",
      "avg / total       0.70      0.70      0.70     19416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sw, predicted_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados das avaliações com tratamento de texto 'Stop Words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito     0     1\n",
      "Real               \n",
      "0        6722  2839\n",
      "1        2931  6924\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(y_test_sw,predicted_sw,rownames=['Real'],colnames=['Predito'],margins=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurária da Predição com Tratamento de texto 'Stop Words' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7028224145035022\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(predicted_sw == y_test_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilização da Técnica de Stemização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stem'] = data.text.apply(lambda x: tratar_texto([x],'stem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_stem = CountVectorizer()\n",
    "vector_stem = vec_stem.fit_transform(data.stem)\n",
    "X_train_stem, X_test_stem, y_train_stem, y_test_stem = train_test_split(vector_stem, data.tag, test_size=0.3, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stem = MultinomialNB().fit(X_train_stem, y_train_stem)\n",
    "predicted_stem = model_stem.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados das avaliações com tratamento de texto 'Stemizado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70      9561\n",
      "          1       0.71      0.71      0.71      9855\n",
      "\n",
      "avg / total       0.70      0.70      0.70     19416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_stem, predicted_stem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusão de resultados 'Stemizados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito     0     1\n",
      "Real               \n",
      "0        6675  2886\n",
      "1        2881  6974\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(y_test_stem,predicted_stem,rownames=['Real'],colnames=['Predito'],margins=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurária da Predição com Tratamento de texto 'Stemizado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7029769262463947\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(predicted_stem == y_test_stem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilização da técnica de Lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemma'] = data.text.apply(lambda x: tratar_texto([x],'lemma'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliações com Tratamento de texto 'Lemmatizado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_lemma = CountVectorizer()\n",
    "vector_lemma = vec.fit_transform(data.lemma)\n",
    "X_train_lemma, X_test_lemma, y_train_lemma, y_test_lemma = train_test_split(vector_lemma, data.tag, test_size=0.3, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lemma = MultinomialNB().fit(X_train_lemma, y_train_lemma)\n",
    "predicted_lemma = model_lemma.predict(X_test_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.70      0.70      9561\n",
      "          1       0.71      0.70      0.70      9855\n",
      "\n",
      "avg / total       0.70      0.70      0.70     19416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_lemma, predicted_lemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurária da Predição com Tratamento de texto 'Lematizado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7008137618459003\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(predicted_lemma == y_test_lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito     0     1    All\n",
      "Real                      \n",
      "0        6698  2863   9561\n",
      "1        2946  6909   9855\n",
      "All      9644  9772  19416\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(y_test_lemma,predicted_lemma,rownames=['Real'],colnames=['Predito'],margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram obtidos melhores resultados considerando o texto puro, sem nenhum tratamento de stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Utilizando o dataset disposto no portal, faça:\n",
    "   ## -> extraia o dataset na pasta do notebook\n",
    "   ## -> crie uma função que leia o conteúdo de cada uma das pastas, amazene num dataframe com duas colunas (review, tag)\n",
    "   ## -> utilize a classe de tratamento de texto criada acima para tratar o texto\n",
    "   ## -> crie um pipeline de classificação de texto (countvectorizer/tfidfvectorizer,divisão em treino/teste,instância de modelo, fit e predict)\n",
    "   ## -> imprima o relatório de classificação\n",
    "   ## -> OBS: teste várias opções de stemming/lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "criticas = [os.path.join(\".\\\\review_polarity.tar(1)\\\\review_polarity\\\\txt_sentoken\\\\neg\\\\\", nome) for nome in os.listdir(\".\\\\review_polarity.tar(1)\\\\review_polarity\\\\txt_sentoken\\\\neg\\\\\")]\n",
    "elogios = [os.path.join(\".\\\\review_polarity.tar(1)\\\\review_polarity\\\\txt_sentoken\\\\pos\\\\\", nome) for nome in os.listdir(\".\\\\review_polarity.tar(1)\\\\review_polarity\\\\txt_sentoken\\\\pos\\\\\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leitura_arquivos(listas,df,tag):\n",
    "    for lista in listas:\n",
    "        df = df.append(pd.read_csv(lista,sep='\\newline',header=None,names=[\"review\"],index_col=False))\n",
    "        df['tag'] = tag\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positivos = leitura_arquivos(elogios,df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negativos = leitura_arquivos(criticas,df,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_positivos.append(df_negativos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stem = df_final.copy()\n",
    "df_stem[\"review\"] = df_stem.review.apply(lambda x: tratar_texto([x],'stem'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemma = df_final.copy()\n",
    "df_lemma[\"review\"] = df_lemma.review.apply(lambda x: tratar_texto([x],'lemma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analiseTfidVetorizer(df):\n",
    "    vectfidf = TfidfVectorizer()\n",
    "    vetortfidf = vectfidf.fit_transform(df.review)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(vetortfidf, df.tag, test_size=0.3, random_state=42)\n",
    "    model_stem = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted = model_stem.predict(X_test)\n",
    "    print('------------------------------------------------------')\n",
    "    print('Classificação')\n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('------------------------------------------------------')\n",
    "    print(\"Matriz de Confusão\")\n",
    "    print(pd.crosstab(y_test,predicted,rownames=['Real'],colnames=['Predito'],margins=False))\n",
    "    print('------------------------------------------------------')\n",
    "    print('Acurácia')\n",
    "    print(np.mean(predicted == y_test))\n",
    "    print('------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analiseCountVetorizer(df):\n",
    "    vectfidf = CountVectorizer()\n",
    "    vetortfidf = vectfidf.fit_transform(df.review)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(vetortfidf, df.tag, test_size=0.3, random_state=42)\n",
    "    model_stem = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted = model_stem.predict(X_test)\n",
    "    print('------------------------------------------------------')\n",
    "    print('Classificação')\n",
    "    print(classification_report(y_test, predicted))\n",
    "    print('------------------------------------------------------')\n",
    "    print(\"Matriz de Confusão\")\n",
    "    print(pd.crosstab(y_test,predicted,rownames=['Real'],colnames=['Predito'],margins=False))\n",
    "    print('------------------------------------------------------')\n",
    "    print('Acurácia')\n",
    "    print(np.mean(predicted == y_test))\n",
    "    print('------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relatórios de Classificações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidVetorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Classificação\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.68      0.70      9556\n",
      "          1       0.70      0.74      0.72      9860\n",
      "\n",
      "avg / total       0.71      0.71      0.71     19416\n",
      "\n",
      "------------------------------------------------------\n",
      "Matriz de Confusão\n",
      "Predito     0     1\n",
      "Real               \n",
      "0        6473  3083\n",
      "1        2581  7279\n",
      "------------------------------------------------------\n",
      "Acurácia\n",
      "0.7082818294190358\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "analiseTfidVetorizer(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Classificação\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.66      0.69      9556\n",
      "          1       0.70      0.75      0.72      9860\n",
      "\n",
      "avg / total       0.71      0.71      0.71     19416\n",
      "\n",
      "------------------------------------------------------\n",
      "Matriz de Confusão\n",
      "Predito     0     1\n",
      "Real               \n",
      "0        6343  3213\n",
      "1        2489  7371\n",
      "------------------------------------------------------\n",
      "Acurácia\n",
      "0.7063246806757314\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "analiseTfidVetorizer(df_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Classificação\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.67      0.69      9556\n",
      "          1       0.70      0.74      0.72      9860\n",
      "\n",
      "avg / total       0.70      0.70      0.70     19416\n",
      "\n",
      "------------------------------------------------------\n",
      "Matriz de Confusão\n",
      "Predito     0     1\n",
      "Real               \n",
      "0        6368  3188\n",
      "1        2566  7294\n",
      "------------------------------------------------------\n",
      "Acurácia\n",
      "0.703646477132262\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "analiseTfidVetorizer(df_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVetorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Classificação\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70      9556\n",
      "          1       0.71      0.71      0.71      9860\n",
      "\n",
      "avg / total       0.71      0.71      0.71     19416\n",
      "\n",
      "------------------------------------------------------\n",
      "Matriz de Confusão\n",
      "Predito     0     1\n",
      "Real               \n",
      "0        6732  2824\n",
      "1        2894  6966\n",
      "------------------------------------------------------\n",
      "Acurácia\n",
      "0.7055006180469716\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "analiseCountVetorizer(df_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Classificação\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.72      0.71      9556\n",
      "          1       0.72      0.69      0.71      9860\n",
      "\n",
      "avg / total       0.71      0.71      0.71     19416\n",
      "\n",
      "------------------------------------------------------\n",
      "Matriz de Confusão\n",
      "Predito     0     1\n",
      "Real               \n",
      "0        6873  2683\n",
      "1        3028  6832\n",
      "------------------------------------------------------\n",
      "Acurácia\n",
      "0.705861145447054\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "analiseCountVetorizer(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Classificação\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.70      0.70      9556\n",
      "          1       0.71      0.70      0.71      9860\n",
      "\n",
      "avg / total       0.70      0.70      0.70     19416\n",
      "\n",
      "------------------------------------------------------\n",
      "Matriz de Confusão\n",
      "Predito     0     1\n",
      "Real               \n",
      "0        6731  2825\n",
      "1        2939  6921\n",
      "------------------------------------------------------\n",
      "Acurácia\n",
      "0.7031314379892872\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "analiseCountVetorizer(df_lemma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
